{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **B2B Sales Prediction**\n",
        "## The goal is to predict the quarterly sales to each of the 75 customers"
      ],
      "metadata": {
        "id": "_pv31OZ4r3mV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "4CxFXSHzb6MG"
      },
      "outputs": [],
      "source": [
        
        "import pandas as pd\n",
        "# Read all CSV files into pandas dataframe\n",
        "economic_indicators_df = pd.read_csv(\"EconomicIndicators.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df = pd.read_csv(\"train.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Merging helpful Economic Indicator data** :     \n",
        "### Along with the train data , Economic Indicators can be useful for more accurate prediction.\n",
        "### Hence, we try to combine them together in dataframe, for both test and train data."
      ],
      "metadata": {
        "id": "ZdchRXivsGjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we convert month to Quarter\n",
        "def month_to_quarter(month):\n",
        "    if month in range(1, 4):\n",
        "        return 'Q1'\n",
        "    elif month in range(4, 7):\n",
        "        return 'Q2'\n",
        "    elif month in range(7, 10):\n",
        "        return 'Q3'\n",
        "    elif month in range(10, 13):\n",
        "        return 'Q4'\n",
        "    elif month in range(13, 16):\n",
        "        return 'Q5'\n",
        "    elif month in range(16, 19):\n",
        "        return 'Q6'\n",
        "    elif month in range(19, 22):\n",
        "        return 'Q7'\n",
        "    elif month in range(22, 25):\n",
        "        return 'Q8'\n",
        "    elif month in range(25, 29):\n",
        "        return 'Q9'\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "9PTwQYNHdQcC"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add column 'Quarter' and remove 'Month' as we need to predict sales based on Quarter\n",
        "economic_indicators_df['Quarter'] = economic_indicators_df['Month'].apply(month_to_quarter)\n",
        "economic_indicators_df = economic_indicators_df.drop('Month', axis=1)"
      ],
      "metadata": {
        "id": "nFA2EVNrdol2"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the data for same quarter by averaging the data for each row of same quarter\n",
        "economic_indicators_df_grouped = economic_indicators_df.groupby('Quarter').mean()\n",
        "economic_indicators_df_grouped = economic_indicators_df_grouped.reset_index()\n",
        "print(economic_indicators_df_grouped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GI5u51dO5yd",
        "outputId": "15c0b355-2790-413d-a285-cea1d11b56c1"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Quarter  Consumer Sentiment  Interest Rate   PMI  Money Supply  NationalEAI  \\\n",
            "0      Q1           63.133333       1.819736  57.2  20975.900000    48.759005   \n",
            "1      Q2           57.866667       2.947262  56.3  21475.800000    38.324704   \n",
            "2      Q3           56.100000       3.229186  51.9  21648.566667    36.429408   \n",
            "3      Q4           58.800000       3.999262  48.1  21678.400000    41.830051   \n",
            "4      Q5           64.600000       3.802861  47.8  21539.333333    51.604474   \n",
            "5      Q6           62.300000       3.692629  48.3  21326.433333    47.580357   \n",
            "6      Q7           69.600000       4.311674  48.9  20893.733333    58.820032   \n",
            "7      Q8           64.933333       4.421024  49.2  20846.300000    53.884995   \n",
            "8      Q9           70.625000       3.894113  50.4  20768.450000    62.824546   \n",
            "\n",
            "     EastEAI    WestEAI   SouthEAI   NorthEAI  \n",
            "0  47.290282  48.102173  47.748953  48.759005  \n",
            "1  36.768411  36.676742  38.124071  39.476987  \n",
            "2  35.565655  36.163304  35.214299  39.926052  \n",
            "3  40.472376  40.913394  42.286551  41.634372  \n",
            "4  48.749299  50.452247  51.671275  48.218051  \n",
            "5  45.546077  45.534401  46.983676  50.539749  \n",
            "6  56.252318  57.588629  58.139379  58.936557  \n",
            "7  51.031343  53.519214  54.592408  56.574052  \n",
            "8  62.245183  61.122633  60.598421  64.493784  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join the Economic indicator dataframe with train and test data, so that we can combine them together\n",
        "train_merged = pd.merge(train_df,economic_indicators_df_grouped, how='inner', left_on='Quarter', right_on='Quarter')\n",
        "test_merged = pd.merge(test_df, economic_indicators_df_grouped, how='inner', left_on='Quarter', right_on='Quarter')\n",
        "\n",
        "# Column 'RevenueGrowth' and 'MarketshareChange' have very low value\n",
        "# We make them larger so that the the values of these columns have better significance\n",
        "train_merged['RevenueGrowth'] = train_merged['RevenueGrowth'] * 100\n",
        "train_merged['MarketshareChange'] = train_merged['MarketshareChange'] * 100\n",
        "test_merged['RevenueGrowth'] = test_merged['RevenueGrowth'] * 100\n",
        "test_merged['MarketshareChange'] = test_merged['MarketshareChange'] * 100\n",
        "print(train_merged.head())"
      ],
      "metadata": {
        "id": "xDmMvaCXdp69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba42149-a6fc-4501-ed74-64521c4b6f36"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID Company Quarter  QuickRatio  InventoryRatio  RevenueGrowth  \\\n",
            "0   0   CMP01      Q1        2.02            7.71            5.0   \n",
            "1   9   CMP02      Q1        2.00            5.46           -7.0   \n",
            "2  18   CMP03      Q1        0.70             NaN           -8.0   \n",
            "3  27   CMP04      Q1        2.21            6.88            5.0   \n",
            "4  36   CMP05      Q1        2.22            3.48          -10.0   \n",
            "\n",
            "   MarketshareChange Bond rating Stock rating Region  ...   Sales  \\\n",
            "0               -4.0         CCC          Buy  South  ...  1517.0   \n",
            "1               -2.0         AAA  Strong Sell   West  ...  3376.0   \n",
            "2                0.0          BB         Hold   East  ...  3270.0   \n",
            "3               -2.0         CCC         Hold   East  ...  2267.0   \n",
            "4               -3.0          BB         Sell   East  ...  5697.0   \n",
            "\n",
            "   Consumer Sentiment  Interest Rate   PMI  Money Supply  NationalEAI  \\\n",
            "0           63.133333       1.819736  57.2       20975.9    48.759005   \n",
            "1           63.133333       1.819736  57.2       20975.9    48.759005   \n",
            "2           63.133333       1.819736  57.2       20975.9    48.759005   \n",
            "3           63.133333       1.819736  57.2       20975.9    48.759005   \n",
            "4           63.133333       1.819736  57.2       20975.9    48.759005   \n",
            "\n",
            "     EastEAI    WestEAI   SouthEAI   NorthEAI  \n",
            "0  47.290282  48.102173  47.748953  48.759005  \n",
            "1  47.290282  48.102173  47.748953  48.759005  \n",
            "2  47.290282  48.102173  47.748953  48.759005  \n",
            "3  47.290282  48.102173  47.748953  48.759005  \n",
            "4  47.290282  48.102173  47.748953  48.759005  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for Null values\n",
        "\n",
        "print(train_merged.isnull().sum())\n",
        "print( test_merged.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgWo8-G_d4gw",
        "outputId": "873fcfc5-610e-41cc-94db-9e0938f12efd"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID                      0\n",
            "Company                 0\n",
            "Quarter                 0\n",
            "QuickRatio              0\n",
            "InventoryRatio        152\n",
            "RevenueGrowth           0\n",
            "MarketshareChange       0\n",
            "Bond rating             0\n",
            "Stock rating            0\n",
            "Region                  0\n",
            "Industry                0\n",
            "Sales                 150\n",
            "Consumer Sentiment      0\n",
            "Interest Rate           0\n",
            "PMI                     0\n",
            "Money Supply            0\n",
            "NationalEAI             0\n",
            "EastEAI                 0\n",
            "WestEAI                 0\n",
            "SouthEAI                0\n",
            "NorthEAI                0\n",
            "dtype: int64\n",
            "ID                     0\n",
            "Company                0\n",
            "Quarter                0\n",
            "QuickRatio             0\n",
            "InventoryRatio        32\n",
            "RevenueGrowth          0\n",
            "MarketshareChange      0\n",
            "Bond rating            0\n",
            "Stock rating           0\n",
            "Region                 0\n",
            "Industry               0\n",
            "Consumer Sentiment     0\n",
            "Interest Rate          0\n",
            "PMI                    0\n",
            "Money Supply           0\n",
            "NationalEAI            0\n",
            "EastEAI                0\n",
            "WestEAI                0\n",
            "SouthEAI               0\n",
            "NorthEAI               0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Missing Sales data** :    \n",
        "### We noticed that some rows of train.csv don't have 'Sales' values, which is our target variable.\n",
        "### We use regression to fill these missing 'Sales' values\n",
        "### Below, we used HuberRegression, this was empirical findind after trying out different regressor models\n",
        "### After noticing that final MAE is least when HuberRegressor is used with grid searching over few hyper params, we use the same for missing 'Sales' prediction in train data"
      ],
      "metadata": {
        "id": "giRuGq7PtHaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "train_data_known_Sales = train_merged.dropna(subset=['Sales'])\n",
        "\n",
        "# DataFrame with rows where 'Sales' is missing\n",
        "train_data_missing_Sales = train_merged[train_merged['Sales'].isna()]\n",
        "\n",
        "xx_train_known_sales = train_data_known_Sales.drop('Sales', axis=1)\n",
        "yy_train_known_sales = train_data_known_Sales['Sales']\n",
        "\n",
        "# Define numerical and categorical columns\n",
        "numerical_cols_sales = xx_train_known_sales.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "categorical_cols_sales = xx_train_known_sales.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Pipeline: Standard scaling + Imputation\n",
        "pipeline_sales = ColumnTransformer([\n",
        "    ('num', Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ]), numerical_cols_sales),\n",
        "    ('cat', Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ]), categorical_cols_sales)\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Create a full pipeline with the preprocessing steps and the regressor\n",
        "full_pipeline_sales = Pipeline([\n",
        "    ('preprocessor', pipeline_sales),\n",
        "    ('huber', HuberRegressor(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Define the parameter grid for HuberRegressor\n",
        "param_grid_sales = {\n",
        "    'huber__epsilon': [1.1, 1.35, 1.5],\n",
        "    'huber__alpha': [0.0001, 0.001, 0.01]\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV for hyperparameter tuning\n",
        "grid_search_sales = GridSearchCV(full_pipeline_sales, param_grid_sales, cv=5, scoring='neg_mean_absolute_error')\n",
        "grid_search_sales.fit(xx_train_known_sales, yy_train_known_sales)\n",
        "\n",
        "# Get the best estimator and predict on the test set\n",
        "best_pipeline_sales = grid_search_sales.best_estimator_\n",
        "\n",
        "# Predict missing 'Sales' values\n",
        "train_data_missing_Sales['Sales'] = best_pipeline_sales.predict(train_data_missing_Sales)\n",
        "\n",
        "# Fill the original DataFrame\n",
        "train_merged.loc[train_merged['Sales'].isna(), 'Sales'] = train_data_missing_Sales['Sales']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnmvC-XKcHrj",
        "outputId": "55109f31-c1a7-4c95-b3f7-a58573618a7e"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "<ipython-input-201-f0e0164eac98>:63: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_data_missing_Sales['Sales'] = best_pipeline_sales.predict(train_data_missing_Sales)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null values after filling missing Sales in train data\n",
        "\n",
        "print(train_merged.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LQ2Bj85gOQV",
        "outputId": "5eebcb29-1a36-4635-9dcc-f5d6b468569c"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID                      0\n",
            "Company                 0\n",
            "Quarter                 0\n",
            "QuickRatio              0\n",
            "InventoryRatio        152\n",
            "RevenueGrowth           0\n",
            "MarketshareChange       0\n",
            "Bond rating             0\n",
            "Stock rating            0\n",
            "Region                  0\n",
            "Industry                0\n",
            "Sales                   0\n",
            "Consumer Sentiment      0\n",
            "Interest Rate           0\n",
            "PMI                     0\n",
            "Money Supply            0\n",
            "NationalEAI             0\n",
            "EastEAI                 0\n",
            "WestEAI                 0\n",
            "SouthEAI                0\n",
            "NorthEAI                0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values in 'InventoryRatio' for both training and test sets\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "train_merged['InventoryRatio'] = imputer.fit_transform(train_merged[['InventoryRatio']])\n",
        "test_merged['InventoryRatio'] = imputer.transform(test_merged[['InventoryRatio']])\n"
      ],
      "metadata": {
        "id": "k4vjLe47hKKg"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final check for null values and check for description\n",
        "\n",
        "print(train_merged.isnull().sum())\n",
        "print(test_merged.isnull().sum())\n",
        "print(train_merged.describe())\n",
        "print(test_merged.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynv38SzBhbty",
        "outputId": "ef655f7e-ab7a-49c9-a1b2-aa9531a2be87"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID                    0\n",
            "Company               0\n",
            "Quarter               0\n",
            "QuickRatio            0\n",
            "InventoryRatio        0\n",
            "RevenueGrowth         0\n",
            "MarketshareChange     0\n",
            "Bond rating           0\n",
            "Stock rating          0\n",
            "Region                0\n",
            "Industry              0\n",
            "Sales                 0\n",
            "Consumer Sentiment    0\n",
            "Interest Rate         0\n",
            "PMI                   0\n",
            "Money Supply          0\n",
            "NationalEAI           0\n",
            "EastEAI               0\n",
            "WestEAI               0\n",
            "SouthEAI              0\n",
            "NorthEAI              0\n",
            "dtype: int64\n",
            "ID                    0\n",
            "Company               0\n",
            "Quarter               0\n",
            "QuickRatio            0\n",
            "InventoryRatio        0\n",
            "RevenueGrowth         0\n",
            "MarketshareChange     0\n",
            "Bond rating           0\n",
            "Stock rating          0\n",
            "Region                0\n",
            "Industry              0\n",
            "Consumer Sentiment    0\n",
            "Interest Rate         0\n",
            "PMI                   0\n",
            "Money Supply          0\n",
            "NationalEAI           0\n",
            "EastEAI               0\n",
            "WestEAI               0\n",
            "SouthEAI              0\n",
            "NorthEAI              0\n",
            "dtype: int64\n",
            "               ID  QuickRatio  InventoryRatio  RevenueGrowth  \\\n",
            "count  675.000000  675.000000      675.000000     675.000000   \n",
            "mean   394.555556    1.603867        4.265124      -0.973333   \n",
            "std    204.960069    0.595615        2.735749       6.739044   \n",
            "min      0.000000    0.500000        1.260000     -20.000000   \n",
            "25%    216.500000    0.990000        2.815000      -7.000000   \n",
            "50%    433.000000    1.730000        4.100000       0.000000   \n",
            "75%    579.000000    2.155000        4.272562       5.000000   \n",
            "max    674.000000    2.490000       24.840000       8.000000   \n",
            "\n",
            "       MarketshareChange         Sales  Consumer Sentiment  Interest Rate  \\\n",
            "count         675.000000    675.000000          675.000000     675.000000   \n",
            "mean           -0.290370   3574.309778           62.086210       3.441780   \n",
            "std             1.762235   1994.512296            4.413928       0.771876   \n",
            "min            -5.000000    864.000000           56.100000       1.819736   \n",
            "25%            -1.500000   2087.393160           57.866667       2.947262   \n",
            "50%             0.000000   3056.000000           62.300000       3.692629   \n",
            "75%             1.000000   4521.931212           64.600000       3.999262   \n",
            "max             2.000000  11686.000000           70.625000       4.421024   \n",
            "\n",
            "              PMI  Money Supply  NationalEAI     EastEAI     WestEAI  \\\n",
            "count  675.000000    675.000000   675.000000  675.000000  675.000000   \n",
            "mean    51.125630  21334.610099    46.827508   45.015353   45.700164   \n",
            "std      3.648236    309.622285     7.668518    7.234131    7.556403   \n",
            "min     47.800000  20768.450000    36.429408   35.565655   36.163304   \n",
            "25%     48.100000  20975.900000    38.324704   36.768411   36.676742   \n",
            "50%     48.900000  21475.800000    47.580357   45.546077   45.534401   \n",
            "75%     56.300000  21648.566667    51.604474   48.749299   50.452247   \n",
            "max     57.200000  21678.400000    62.824546   62.245183   61.122633   \n",
            "\n",
            "         SouthEAI    NorthEAI  \n",
            "count  675.000000  675.000000  \n",
            "mean    46.359454   47.495026  \n",
            "std      7.623788    7.063415  \n",
            "min     35.214299   39.476987  \n",
            "25%     38.124071   39.926052  \n",
            "50%     46.983676   48.218051  \n",
            "75%     51.671275   50.539749  \n",
            "max     60.598421   64.493784  \n",
            "               ID  QuickRatio  InventoryRatio  RevenueGrowth  \\\n",
            "count  150.000000  150.000000      150.000000     150.000000   \n",
            "mean   340.500000    1.602867        4.026693      -0.126667   \n",
            "std    195.491765    0.585409        1.907124       5.971180   \n",
            "min      7.000000    0.520000        1.390000     -18.000000   \n",
            "25%    172.000000    1.075000        2.910000      -4.000000   \n",
            "50%    340.500000    1.745000        3.845000       1.000000   \n",
            "75%    509.000000    2.090000        4.265124       4.000000   \n",
            "max    674.000000    2.480000       17.110000       8.000000   \n",
            "\n",
            "       MarketshareChange  Consumer Sentiment  Interest Rate        PMI  \\\n",
            "count         150.000000          150.000000     150.000000  150.00000   \n",
            "mean           -0.266667           67.779167       4.157569   49.80000   \n",
            "std             1.632993            2.855367       0.264338    0.60201   \n",
            "min            -5.000000           64.933333       3.894113   49.20000   \n",
            "25%            -1.000000           64.933333       3.894113   49.20000   \n",
            "50%             0.000000           67.779167       4.157569   49.80000   \n",
            "75%             1.000000           70.625000       4.421024   50.40000   \n",
            "max             2.000000           70.625000       4.421024   50.40000   \n",
            "\n",
            "       Money Supply  NationalEAI     EastEAI     WestEAI    SouthEAI  \\\n",
            "count    150.000000   150.000000  150.000000  150.000000  150.000000   \n",
            "mean   20807.375000    58.354771   56.638263   57.320923   57.595414   \n",
            "std       39.055402     4.484750    5.625703    3.814446    3.013067   \n",
            "min    20768.450000    53.884995   51.031343   53.519214   54.592408   \n",
            "25%    20768.450000    53.884995   51.031343   53.519214   54.592408   \n",
            "50%    20807.375000    58.354771   56.638263   57.320923   57.595414   \n",
            "75%    20846.300000    62.824546   62.245183   61.122633   60.598421   \n",
            "max    20846.300000    62.824546   62.245183   61.122633   60.598421   \n",
            "\n",
            "         NorthEAI  \n",
            "count  150.000000  \n",
            "mean    60.533918  \n",
            "std      3.973132  \n",
            "min     56.574052  \n",
            "25%     56.574052  \n",
            "50%     60.533918  \n",
            "75%     64.493784  \n",
            "max     64.493784  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x = train_merged.drop('Sales', axis=1)\n",
        "y = train_merged['Sales']\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "# Print the data types in X_train\n",
        "print(X_train.dtypes)"
      ],
      "metadata": {
        "id": "L3GKDOWKhuqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3e07591-3930-4419-9791-b22823ce90ee"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (540, 20)\n",
            "X_test shape: (135, 20)\n",
            "y_train shape: (540,)\n",
            "y_test shape: (135,)\n",
            "ID                      int64\n",
            "Company                object\n",
            "Quarter                object\n",
            "QuickRatio            float64\n",
            "InventoryRatio        float64\n",
            "RevenueGrowth         float64\n",
            "MarketshareChange     float64\n",
            "Bond rating            object\n",
            "Stock rating           object\n",
            "Region                 object\n",
            "Industry               object\n",
            "Consumer Sentiment    float64\n",
            "Interest Rate         float64\n",
            "PMI                   float64\n",
            "Money Supply          float64\n",
            "NationalEAI           float64\n",
            "EastEAI               float64\n",
            "WestEAI               float64\n",
            "SouthEAI              float64\n",
            "NorthEAI              float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Regressor Model** :   \n",
        "### Based on experiments , I found that HuberRegressor, which fits well for data with outliers , is the best fit for given data\n",
        "### Here we run GridSearch over different hyper params for HuberRegressor and find best model"
      ],
      "metadata": {
        "id": "GhHPgQdGthFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on experiments , I found that HuberRegressor, which fits well for data with outliers , is the best fit for given data\n",
        "# Here we run GridSearch over different hyper params for HuberRegressor and find best model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Define numerical and categorical columns\n",
        "numerical_cols = X_train.select_dtypes(include=[np.number]).columns\n",
        "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Pipeline: Standard scaling + Imputation\n",
        "pipeline = ColumnTransformer([\n",
        "    ('num', Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ]), numerical_cols),\n",
        "    ('cat', Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ]), categorical_cols)\n",
        "])\n",
        "\n",
        "# Create a full pipeline with the preprocessing steps and the regressor\n",
        "full_pipeline = Pipeline([\n",
        "    ('preprocessor', pipeline),\n",
        "    ('huber', HuberRegressor(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Define the parameter grid for HuberRegressor\n",
        "param_grid = {\n",
        "    'huber__epsilon': [1.1, 1.35, 1.5],\n",
        "    'huber__alpha': [0.0001, 0.001, 0.01]\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV for hyperparameter tuning\n",
        "grid_search = GridSearchCV(full_pipeline, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
        "# Note that we use entire data (X_train + X_test , Y_train + y_test), so that it performs better on Kaggle test data\n",
        "grid_search.fit(x, y)\n",
        "\n",
        "# Get the best estimator and predict on the test data\n",
        "best_pipeline = grid_search.best_estimator_\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best Mean Absolute Error:\", -grid_search.best_score_)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model using mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n"
      ],
      "metadata": {
        "id": "MXgAhTIXUs5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d8d9d2a-6b47-4fc4-927a-234cc5ca3a6d"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'huber__alpha': 0.0001, 'huber__epsilon': 1.35}\n",
            "Best Mean Absolute Error: 596.6477425740948\n",
            "Mean Absolute Error: 555.0115793329742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run prediction on test data and create final submission file csv"
      ],
      "metadata": {
        "id": "VS8WYznltvKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test_merged DataFrame, which is Kaggle test data\n",
        "test_predictions = best_pipeline.predict(test_merged)\n",
        "\n",
        "# Create the result DataFramepd.DataFrame({'ID': test_merged['ID'], 'Sales': (test_prediction)})\n",
        "result_for_submission = pd.DataFrame({'Id': test_merged['ID'], 'Sales': test_predictions})\n",
        "print(result_for_submission)\n",
        "# Creat csv file for submission\n",
        "result_for_submission.to_csv('result_for_submission.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whN-UkYkOf4I",
        "outputId": "446ae4e8-6097-45ad-9ec7-55bcb0ad73eb"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Id        Sales\n",
            "0      7  1672.879531\n",
            "1     16  3659.382330\n",
            "2     25  5403.646922\n",
            "3     34  2389.800212\n",
            "4     43  5772.560666\n",
            "..   ...          ...\n",
            "145  638  4328.990780\n",
            "146  647  1674.980026\n",
            "147  656  5967.521396\n",
            "148  665  2923.473050\n",
            "149  674  1695.158551\n",
            "\n",
            "[150 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y2aJ8rAhWg7k"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0HnbkhYRuWPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VhNfCh7IuWhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EZrqsSE3uW0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hrckriVluXDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "er6uLKI8uXYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gwJAoP1XuXo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2sNxwkJuX8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SvKX_I72uYO2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
